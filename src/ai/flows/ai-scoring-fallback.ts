'use server';

/**
 * @fileOverview This file implements the AI scoring fallback flow.
 *
 * - aiScoringFallback - A function that uses an AI model to evaluate student annotations if the defined scoring rules fail.
 * - AiScoringFallbackInput - The input type for the aiScoringFallback function.
 * - AiScoringFallbackOutput - The return type for the aiScoringFallback function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const AiScoringFallbackInputSchema = z.object({
  gtAnnotations: z.string().describe('Ground truth annotations in JSON format.'),
  studentAnnotations: z.string().describe('Student annotations in JSON format.'),
  toolType: z.string().describe('The type of annotation tool used (e.g., bounding_box, polygon).'),
  errorDetails: z.string().describe('Details of the error that occurred during the primary scoring process, including the traceback.'),
});
export type AiScoringFallbackInput = z.infer<typeof AiScoringFallbackInputSchema>;

const AiScoringFallbackOutputSchema = z.object({
  score: z.number().describe('Final percentage score (0-100) approximated by the AI model.'),
  feedback: z.array(z.string()).describe('A list of human-readable suggestions generated by the AI model.'),
  issues: z.array(z.string()).optional().describe('A list of short identified issues by the AI model.'),
});
export type AiScoringFallbackOutput = z.infer<typeof AiScoringFallbackOutputSchema>;

export async function aiScoringFallback(input: AiScoringFallbackInput): Promise<AiScoringFallbackOutput> {
  return aiScoringFallbackFlow(input);
}

const aiScoringFallbackPrompt = ai.definePrompt({
  name: 'aiScoringFallbackPrompt',
  input: {schema: AiScoringFallbackInputSchema},
  output: {schema: AiScoringFallbackOutputSchema},
  prompt: `You are an expert in data annotation, computer vision, and AI-assisted quality control. 
    Your task is to evaluate image annotation submissions made by students, when the standard evaluation logic has failed.
    Provide a score and feedback based on the information provided to approximate correctness.

    Ground Truth Annotations: {{{gtAnnotations}}}
    Student Annotations: {{{studentAnnotations}}}
    Annotation Tool Type: {{{toolType}}}
    Error Details: {{{errorDetails}}}

    Based on the student annotations compared to ground truth, and considering the error that occurred during the primary scoring,
    provide an approximate score (0-100) and a list of feedback suggestions to help the student improve. Also list identified issues.
    Return the results as a JSON object.

    Ensure that your evaluation and feedback are technically accurate and understandable to a non-engineer. 
`,
});

const aiScoringFallbackFlow = ai.defineFlow(
  {
    name: 'aiScoringFallbackFlow',
    inputSchema: AiScoringFallbackInputSchema,
    outputSchema: AiScoringFallbackOutputSchema,
  },
  async input => {
    const {output} = await aiScoringFallbackPrompt(input);
    return output!;
  }
);
